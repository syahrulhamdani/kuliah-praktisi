{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a6e41b-90a2-4c88-9bab-0482c72f04ea",
   "metadata": {},
   "source": [
    "# CNN for Image Classification\n",
    "\n",
    "Halo, semuanya! üëãüèª\n",
    "\n",
    "Selamat datang di Kuliah Praktisi \"Jaringan Syaraf Tiruan\" atau *Artificial Neural Networks*. Mari kita kenalan dulu!\n",
    "\n",
    "* Saya **Syahrul Bahar Hamdani**, panggil aja **Dani**\n",
    "* Matematika 2012, lulus 2016. Ambil ROK, pakai PSO untuk Penjadwalan Meeting di skripsi, dibimbing oleh Pak Herry dan Bu Auli üôèüèª\n",
    "* Ambil S2 Sains Komputasi ITB tahun 2017 dan lulus 2019. Ambil tesis berjudul \"**_Predictive Maintenance_ Mesin Pesawat dengan Pendekatan _Machine Learning_**\" ([bukti](https://digilib.itb.ac.id/index.php/gdl/view/35771)) yang dibimbing oleh Bu Nuning Nuraini\n",
    "* Sekarang bekerja sebagai **Lead Data Scientist** di [KoinWorks](https://koinworks.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ea923-b74f-43a2-a6e8-97e5697965c8",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "Di notebook ini, kita akan bahas bagaimana membuat model deep learning CNN untuk klasifikasi gambar. Kita akan coba menggunakan _top-down_ approach, dimulai dari hasil akhir model, kemudian kita akan coba bedah komponen penyusunnya.\n",
    "\n",
    "Agenda kita hari ini:\n",
    "* CNN dengan PyTorch\n",
    "* Kenapa menggunakan CNN?\n",
    "* Bagaimana cara kerja CNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8803448-bf1a-419b-9c00-c19661c008c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d0250-681e-456c-aa4d-376a88526c2e",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "[Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08adc908-c4c3-4e79-9d6d-9f898c11d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        batch = pickle.load(fo, encoding='bytes')\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b82ba-4e0a-40f2-90fa-003af0e19af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "CIFAR_DIR = DATA_DIR / \"cifar-10-batches-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2485b-dceb-4b6e-aadd-9419a6845350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(DATA_DIR, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(DATA_DIR, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35f0b2-1fb8-4e2e-a56e-816f4389c923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_cifar(is_train=True):\n",
    "    train_list = [\n",
    "        \"data_batch_1\",\n",
    "        \"data_batch_2\",\n",
    "        \"data_batch_3\",\n",
    "        \"data_batch_4\",\n",
    "        \"data_batch_5\",\n",
    "    ]\n",
    "    test_list = [\n",
    "        \"test_batch\",\n",
    "    ]\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "    }\n",
    "\n",
    "    if is_train:\n",
    "        downloaded_list = train_list\n",
    "    else:\n",
    "        downloaded_list = test_lit\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # load image data\n",
    "    for file_name in downloaded_list:\n",
    "        file_path = CIFAR_DIR / file_name\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            entry = pickle.load(f, encoding=\"latin1\")\n",
    "            data.append(entry[\"data\"])\n",
    "            if \"labels\" in entry:\n",
    "                labels.extend(entry[\"labels\"])\n",
    "            else:\n",
    "                labels.extend(entry[\"fine_labels\"])\n",
    "\n",
    "    data = np.vstack(data).reshape(-1, 3, 32, 32)\n",
    "    data = data.transpose(0, 2, 3, 1)\n",
    "\n",
    "    # load metadata\n",
    "    meta_file_path = CIFAR_DIR / meta[\"filename\"]\n",
    "    with open(meta_file_path, \"rb\") as infile:\n",
    "        metadata = pickle.load(infile, encoding=\"latin1\")\n",
    "        classes = metadata[meta[\"key\"]]\n",
    "    class_to_idx = {_class: i for i, _class in enumerate(classes)}\n",
    "\n",
    "    return data, labels, classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b81311-1653-439e-9ddd-0cfc71e1cfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, train_labels, train_classes, train_class2idx = load_cifar(is_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb93d3b-d319-4e8b-b304-49e229fc0585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_sample_images(images, labels, class_names):\n",
    "    rng = np.random.default_rng()\n",
    "    rand_idx = rng.integers(0, len(train_labels), 25)\n",
    "    img_samples = images[rand_idx]\n",
    "    label_samples = [class_names[labels[idx]] for idx in rand_idx]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8), tight_layout=True)\n",
    "    for ax in range(1, 26):\n",
    "        fig.add_subplot(5, 5, ax)\n",
    "        plt.imshow(img_samples[ax-1])\n",
    "        plt.title(label_samples[ax-1])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897cfbf-c4e2-457f-8f4c-8db4aab076e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_sample_images(train_data, train_labels, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de333b3b-5b35-4569-b3ef-bee5dd9a0220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50404e-4704-4c2b-af53-4b82eb62f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b06981-7cbb-4b1b-a451-d484fff2d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5672b-8038-42fb-9bb3-f2ff27c76ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_channels = list(IMAGE_DATA_DIR.glob(\"*\"))\n",
    "print(\"Num of channels:\", len(list_channels))\n",
    "\n",
    "for channel in list_channels:\n",
    "    print(\"sample video from '{}':\".format(channel.name))\n",
    "    for video in channel.glob(\"*.jpg\"):\n",
    "        video_id = video.name.split(\".\")[0]\n",
    "        print(\"video name:\", video, \"category:\", df_metadata.loc[df_metadata.Id.isin([video_id]), \"Category\"].item())\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
